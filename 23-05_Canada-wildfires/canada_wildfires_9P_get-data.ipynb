{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "125cbf12-584e-4158-99f4-7db854c0134e",
   "metadata": {},
   "source": [
    "# **Additional scripts used to acquire & pre-process FWI data**\n",
    "Note: these scripts were run either on JASMIN or on the Imperial HPC, depending on the data source.  \n",
    "Data sources and any further instructions are given in each section below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a999d3-af72-4d9b-b034-8fde01ddd40d",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "---\n",
    "# **ERA5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a60abf-e0cf-49d1-85f0-23b4db2fa9c6",
   "metadata": {},
   "source": [
    "## **Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c839e1ff-3609-4c9d-aeea-bb7d5c8d2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = xr.open_dataset(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/era5/downloaded_era5_t2m-d2m-snd.nc\").sum(\"expver\", keep_attrs = True)\n",
    "uv = xr.open_dataset(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/era5/downloaded_era5_u10-v10.nc\").sum(\"expver\", keep_attrs = True)\n",
    "j31 = xr.open_dataset(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/era5/downloaded_era5_July-31st.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5fa110-27db-405e-92e6-9f7104a0e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.concat([tds.t2m, j31.t2m], \"time\").to_netcdf(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/era5/era5_t2m_19400101-20230731.nc\")\n",
    "xr.concat([tds.d2m, j31.d2m], \"time\").to_netcdf(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/era5/era5_d2m_19400101-20230731.nc\")\n",
    "xr.concat([tds.sd, j31.sd], \"time\").to_netcdf(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/era5/era5_sd_19400101-20230731.nc\")\n",
    "\n",
    "xr.concat([uv, j31[[\"u10\",\"v10\"]]], \"time\").to_netcdf(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/era5/era5_uv_19400101-20230731.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd1ae8-eb13-4bc6-b100-e6a52a63caf0",
   "metadata": {},
   "source": [
    "## **Calculate FWI for corrected ERA5 data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a8a332-89ac-4f64-8b83-a04cb3f59fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas, sfcWind, snw, hurs = [xr.open_dataset(\"../00_WWA_project_folder/ephemeral/canada_fwi/fwi/era5/\"+varnm+\"_era5_19400101_20230731.nc\")[varnm] for varnm in [\"tas\", \"sfcWind\", \"sd\", \"hurs\"]]\n",
    "pr = xr.open_dataset(\"era5_tp_19400101-20230731_corrected.nc\").tp\n",
    "\n",
    "months = tas.time.dt.month.to_numpy()\n",
    "days = tas.time.dt.day.to_numpy()\n",
    "\n",
    "print(\"  \",datetime.now())\n",
    "ffmc, dmc, dc, isi, bui, fwi = xr.apply_ufunc(lambda t, p, w, h, s : calculate_fwi(months, days, t, p, w, h, s), tas, pr, sfcWind, hurs, snw, \n",
    "                                              input_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], \n",
    "                                              output_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], vectorize = True)\n",
    "print(\"  \",datetime.now())\n",
    "\n",
    "da = xr.merge([eval(v).rename(v) for v in [\"ffmc\", \"dmc\", \"dc\", \"isi\", \"bui\", \"fwi\"]])\n",
    "da.to_netcdf(\"model_fwi/fwi_era5.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9385417-90b3-4fd2-ba71-3eea01df1a63",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "---\n",
    "# **CanESM2-CanRCM4 large ensemble**\n",
    "_All processing carried out on Imperial's HPC_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016d47c1-6930-4085-a6a2-fe0960a2681d",
   "metadata": {},
   "source": [
    "## **Define coordinate reference system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5993f3-9e5e-4280-8345-26eb3800d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_proj = cartopy.crs.RotatedPole(pole_longitude = 83, pole_latitude = 43)\n",
    "sf = gpd.read_csv(\"sf_ejb/\").to_crs(lens_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c5716-0b5d-4197-86d5-dc88450ee33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that CRS is correct\n",
    "da = xr.open_dataset(\"../00_WWA_project_folder/ephemeral/canada_fwi/can_lens/r1_r1/tas_NAM-44_CCCma-CanESM2_historical-r1_r1i1p1_CCCma-CanRCM4_r2_3hr_1950010103-1951010100.nc\").tas\n",
    "rm = regionmask.mask_3D_geopandas(sf, da.rlon, da.rlat).squeeze(drop = True)\n",
    "\n",
    "da.isel(time = -1).plot()\n",
    "sf.boundary.plot(color = \"k\", ax = plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f9ce3-ce15-443c-a515-2758975f1830",
   "metadata": {},
   "source": [
    "## **Download raw data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65eab4ff-bc97-4074-8df8-3d27d7486eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab32f8-2c65-4d94-b5d2-cbf54954d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all GCM & RCM realisations and use wget to download the data into the current directory\n",
    "\n",
    "fpath = \"https://crd-data-donnees-rdc.ec.gc.ca/CCCMA/products/CanSISE/output/CCCma/CanRCM4/\"\n",
    "for gcm in [\"r\"+str(i) for i in range(1,6)]:\n",
    "    for rcm in [\"r\"+str(i) for i in range(1,8)]:\n",
    "        \n",
    "        newdir = gcm+\"_\"+rcm\n",
    "        if not os.path.exists(newdir):\n",
    "            ! mkdir -p ${newdir} \n",
    "                \n",
    "        # 3-hourly data\n",
    "        for varbl in [\"hurs\", \"tas\", \"pr\", \"sfcWind\"]:\n",
    "            for y in range(1950, 2051):\n",
    "                \n",
    "                fnm = \"NAM-44_CCCma-CanESM2_historical-\"+gcm+\"/3hr/atmos/\"+varbl+\"/\"+rcm+\"i1p1/\"+varbl+\"_NAM-44_CCCma-CanESM2_historical-\"+gcm+\"_\"+rcm+\"i1p1_CCCma-CanRCM4_r2_3hr_\"+str(y)+\"010103-\"+str(y+1)+\"010100.nc\"\n",
    "                if not os.path.exists(newdir+\"/\"+fnm.split(\"/\")[-1]):\n",
    "                    fnm = fpath + fnm+\" -P \"+newdir\n",
    "                    ! wget $fnm\n",
    "                    clear_output(wait = False) \n",
    "            \n",
    "        # daily data\n",
    "        for varbl in [\"snd\"]:\n",
    "            \n",
    "            fnm = fpath+\"NAM-44_CCCma-CanESM2_historical-\"+gcm+\"/day/atmos/\"+varbl+\"/\"+rcm+\"i1p1/\"+varbl+\"_NAM-44_CCCma-CanESM2_historical-\"+gcm+\"_\"+rcm+\"i1p1_CCCma-CanRCM4_r2_day_19500101-19501231.nc -P \"+gcm+\"_\"+rcm\n",
    "            \n",
    "            for y in range(1951, 2051, 5):\n",
    "                fnm = \"NAM-44_CCCma-CanESM2_historical-\"+gcm+\"/day/atmos/\"+varbl+\"/\"+rcm+\"i1p1/\"+varbl+\"_NAM-44_CCCma-CanESM2_historical-\"+gcm+\"_\"+rcm+\"i1p1_CCCma-CanRCM4_r2_day_\"+str(y)+\"0101-\"+str(y+4)+\"1231.nc\"\n",
    "                if not os.path.exists(gcm+\"_\"+rcm+\"/\"+fnm.split(\"/\")[-1]):\n",
    "                    fnm = fpath+fnm+\" -P \"+gcm+\"_\"+rcm\n",
    "                    ! wget $fnm\n",
    "                    clear_output(wait = False)\n",
    "        \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e6fc5-36a2-4c11-9df2-e52916ee732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all files are successfully downloaded, no partial data\n",
    "[sorted([str(round(os.stat(f).st_size/1024/1024))+\" \"+f for f in glob.glob(\"r1_r\"+str(r+1)+\"/*.nc\")])[:5] for r in range(7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1859223-0a19-435e-9174-f89f6101b1a6",
   "metadata": {},
   "source": [
    "## **Pre-processing**\n",
    "Initial subsetting carried out using CDO  \n",
    "Concatenation into single file also done using CDO for tas, hurs, sfcWind, snd - only precip aggregated manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e56057a-8d43-452d-b303-a1b798fed828",
   "metadata": {},
   "source": [
    "### **Subset data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b54236-62bb-4854-a3fc-543a73d03a25",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "# script to subset each subfile of the large ensemble (concatenation done separately)\n",
    "module load cdo\n",
    "\n",
    "# temperature (only 18:00)\n",
    "fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/can_lens/*/tas_*.nc`\n",
    "for file_in in $fl; do\n",
    "    file_out=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/canesm-canrcm/subfiles/${file_in##*/};\n",
    "    cdo -s selhour,18 -sellonlatbox,280,297,47,59 $file_in $file_out;\n",
    "done\n",
    "echo \"tas complete\"\n",
    "\n",
    "# relative humidity (only 18:00)\n",
    "fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/can_lens/*/hurs_*.nc`\n",
    "for file_in in $fl; do\n",
    "    file_out=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/canesm-canrcm/subfiles/${file_in##*/};\n",
    "    cdo -s selhour,18 -sellonlatbox,280,297,47,59 $file_in $file_out;\n",
    "done\n",
    "echo \"hurs complete\"\n",
    "\n",
    "# wind speed (only 18:00)\n",
    "fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/can_lens/*/sfcWind_*.nc`\n",
    "for file_in in $fl; do\n",
    "    file_out=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/canesm-canrcm/subfiles/${file_in##*/};\n",
    "    cdo -s selhour,18 -sellonlatbox,280,297,47,59 $file_in $file_out;\n",
    "done\n",
    "echo \"sfcWind complete\"\n",
    "\n",
    "# precip (keep all timesteps)\n",
    "fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/can_lens/*/pr_*.nc`\n",
    "for file_in in $fl; do\n",
    "    file_out=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/canesm-canrcm/subfiles/${file_in##*/};\n",
    "    cdo -s sellonlatbox,280,297,47,59 $file_in $file_out;\n",
    "done\n",
    "echo \"pr complete\"\n",
    "\n",
    "# snow depth (keep all timesteps)\n",
    "fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/can_lens/*/snd_*.nc`\n",
    "for file_in in $fl; do\n",
    "    file_out=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/canesm-canrcm/subfiles/${file_in##*/};\n",
    "    cdo -s sellonlatbox,280,297,47,59 $file_in $file_out;\n",
    "done;\n",
    "echo \"snd complete\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccd8c01-6b18-4a07-97cf-7c30897254fb",
   "metadata": {},
   "source": [
    "### **Concatenate subsetted data (excluding precip)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a584df-28b4-48d3-ac31-773e495b5599",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "# script to concatenate subsets into single file per variable (subsetting done separately)\n",
    "module load cdo\n",
    "\n",
    "for varnm in tas hurs sfcWind snd; do\n",
    "    for gcm in `seq 1 5`; do \n",
    "        for rcm in `seq 1 7`; do \n",
    "\n",
    "            fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/canesm-canrcm/subfiles/${varnm}_NAM-44_CCCma-CanESM2_historical-r${gcm}_r${rcm}i1p1_CCCma-CanRCM4_r2_*.nc`;\n",
    "            new_fnm=canesm-canrcm/${varnm}_NAM-44_CCCma-CanESM2_historical-r${gcm}_r${rcm}i1p1_CCCma-CanRCM4_r2.nc;\n",
    "            cdo cat $fl $new_fnm;\n",
    "\n",
    "        done;\n",
    "    done;\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c4af01-9964-4b0e-be2f-283a3a096ea7",
   "metadata": {},
   "source": [
    "### **Concatenate & aggregate precipitation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56ee727-f8ff-41e5-8283-1e72d03c9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/canesm-canrcm/subfiles/\"\n",
    "path_out = \"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/canesm-canrcm/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe220c9-9335-4e50-8bdd-2ce80cb278a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gcm in range(6): \n",
    "    for rcm in range(8):  \n",
    "        \n",
    "        fl = sorted(glob.glob(fpath+\"pr_*r\"+str(gcm)+\"_r\"+str(rcm)+\"*.nc\"))\n",
    "        new_fnm = path_out+fl[0].split(\"/\")[-1][:-28]+\"24hr-1800.nc\"\n",
    "        \n",
    "        da = xr.open_mfdataset(fl).pr\n",
    "        da = da.rolling(time = 8).sum().groupby(\"time.hour\")[18]\n",
    "        da.to_netcdf(new_fnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec8d59-9983-4240-acd0-ade47ef81674",
   "metadata": {},
   "source": [
    "## **Model evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e7878-b0f5-4f22-b2c4-59f97e237ae7",
   "metadata": {},
   "source": [
    "### **Seasonal cycle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ea5da4-db19-4fe4-a6a5-9323457194fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature\n",
    "lens = xr.concat([xr.open_dataset(fnm).sel(time = slice(\"1980\", \"2020\")).tas for fnm in sorted(glob.glob(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/canesm-canrcm/tas_*\"))], \"member\")\n",
    "lens_sc = convert_units_to(lens.where(regionmask.mask_3D_geopandas(sf, lens.lon, lens.lat).squeeze(drop = True) == 1).mean([\"rlat\", \"rlon\"]).groupby(\"time.dayofyear\").mean(), \"degC\")\n",
    "lens_sc.to_csv(\"eval/sc-tas_canesm-canrcm.csv\")\n",
    "\n",
    "# precip\n",
    "lens = xr.concat([xr.open_dataset(fnm).sel(time = slice(\"1980\", \"2020\")).pr for fnm in sorted(glob.glob(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/canesm-canrcm/pr_*\"))], \"member\")\n",
    "lens_sc = convert_units_to(lens.where(regionmask.mask_3D_geopandas(sf, lens.lon, lens.lat).squeeze(drop = True) == 1).mean([\"rlat\", \"rlon\"]).groupby(\"time.dayofyear\").mean(), \"mm/day\")\n",
    "lens_sc.to_csv(\"eval/sc-pr_canesm-canrcm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab534c4-39ad-42ae-a267-59e943f8c6df",
   "metadata": {},
   "source": [
    "### **Spatial pattern**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "aac29ef4-d6d8-441c-870f-0854f99f9008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat-lon bounds for Canada\n",
    "xn = 360-145; xx = 360-50; yn = 40; yx = 80\n",
    "\n",
    "tmplt = xr.open_dataset(\"../00_WWA_project_folder/ephemeral/canada_fwi/can_lens/r1_r1/tas_NAM-44_CCCma-CanESM2_historical-r1_r1i1p1_CCCma-CanRCM4_r2_3hr_1950010103-1951010100.nc\")\n",
    "rm = np.logical_and(np.logical_and(tmplt.lon >= xn, tmplt.lon <= xx), np.logical_and(tmplt.lat >= yn, tmplt.lat <= yx))\n",
    "rm = rm.where(rm == 1).dropna(\"rlon\", \"all\").dropna(\"rlat\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "58544716-20a5-4f51-b0f1-c1a419284cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_tas = []\n",
    "for fp in sorted(glob.glob(\"../00_WWA_project_folder/ephemeral/canada_fwi/can_lens/r[0-9]_r[0-9]\")):\n",
    "    print(fp, end = \"\")\n",
    "    fl = glob.glob(fp+\"/tas_*.nc\")\n",
    "    fl = [fnm for fnm in fl if (fnm[-13:-9] >= \"1980\") and (fnm[-24:-20] <= \"2010\")]\n",
    "    \n",
    "    em = []\n",
    "    for fnm in fl:\n",
    "        print(\".\", end = \"\")\n",
    "        em.append(xr.open_dataset(fnm).tas.sel(rlon = rm.rlon, rlat = rm.rlat).groupby(\"time.season\")[\"JJA\"].mean(\"time\"))\n",
    "    ens_tas.append(xr.concat(em, \"time\"))\n",
    "    print(\"\")\n",
    "\n",
    "lens_tas = convert_units_to(xr.concat(ens_tas, \"member\").mean(\"member\"), \"degC\")\n",
    "lens_tas.to_netcdf(\"sp-tas_NAM-44_CCCma-CanESM2_CCCma-CanRCM4_r2.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "31e7a26a-3a7d-4ac0-9b0c-7e33071ee838",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_pr = []\n",
    "for fp in sorted(glob.glob(\"../00_WWA_project_folder/ephemeral/canada_fwi/can_lens/r[0-9]_r[0-9]\")):\n",
    "    print(fp, end = \"\")\n",
    "    fl = glob.glob(fp+\"/pr_*.nc\")\n",
    "    fl = [fnm for fnm in fl if (fnm[-13:-9] >= \"1980\") and (fnm[-24:-20] <= \"2010\")]\n",
    "    \n",
    "    em = []\n",
    "    for fnm in fl:\n",
    "        print(\".\", end = \"\")\n",
    "        da = xr.open_dataset(fnm).pr.sel(rlon = rm.rlon, rlat = rm.rlat)\n",
    "        em.append(da.sel(time = [m in [3,4,5,6,7] for m in da.time.dt.month]))\n",
    "    em = xr.concat(em, \"time\").mean(\"time\")\n",
    "    ens_pr.append(xr.concat(em, \"time\"))\n",
    "    print(\"\")\n",
    "\n",
    "lens_pr = convert_units_to(xr.concat(zz, \"member\").mean(\"member\"), \"mm/day\")\n",
    "lens_pr.to_netcdf(\"sp-pr_NAM-44_CCCma-CanESM2_CCCma-CanRCM4_r2.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a083f429-ff86-4746-9013-467b85b6cb0d",
   "metadata": {},
   "source": [
    "## **Calculate FWI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8d521d6-57ec-43dd-9363-51c6b3216928",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/canesm-canrcm//\"\n",
    "fl = sorted([\"_\".join(fnm.split(\"_\")[-6:-2]) for fnm in glob.glob(fpath+\"tas_*.nc\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe26484-c110-43ba-90be-2778a11cb1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fnm in fl:\n",
    "    \n",
    "    print(fnm)\n",
    "        \n",
    "    # load data & align timestamps\n",
    "    tas = convert_units_to(xr.open_mfdataset(fpath+\"tas_*\"+fnm+\"*.nc\").tas.load(), \"degC\").sel(rlat = rm.rlat, rlon = rm.rlon, time = slice(\"1951\", None))\n",
    "    pr = convert_units_to(xr.open_mfdataset(fpath+\"pr_*\"+fnm+\"*.nc\").pr.load(), \"mm/day\")\n",
    "    sfcWind = convert_units_to(xr.open_mfdataset(fpath+\"sfcWind_*\"+fnm+\"*.nc\").sfcWind.load(), \"km/hr\")\n",
    "    hurs = xr.open_mfdataset(fpath+\"hurs_*\"+fnm+\"*.nc\").hurs.load()\n",
    "    snw = convert_units_to(xr.open_mfdataset(fpath+\"snd_*\"+fnm+\"*.nc\").snd.load(), \"m\")\n",
    "    \n",
    "    # check that all time series are the same length\n",
    "    if not all([len(da.time) == len(tas.time) for da in [pr, sfcWind, hurs, snw]]):\n",
    "        print(\"   ! length mismatch - skipping\")\n",
    "        continue\n",
    "        \n",
    "    # reassign coords to ensure that data will align correctly\n",
    "    P, W, H, S = [da.sel(rlon = tas.rlon, rlat = tas.rlat, time = slice(\"1951\", None)).assign_coords(time = tas.time) for da in [pr, sfcWind, hurs, snw]]\n",
    "\n",
    "    months = tas.time.dt.month.to_numpy()\n",
    "    days = tas.time.dt.day.to_numpy()\n",
    "    \n",
    "    print(\"  \",datetime.now())\n",
    "    ffmc, dmc, dc, isi, bui, fwi = xr.apply_ufunc(lambda t, p, w, h, s : calculate_fwi(months, days, t, p, w, h, s), tas, P, W, H, S, \n",
    "                                                  input_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], \n",
    "                                                  output_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], vectorize = True)\n",
    "    print(\"  \",datetime.now())\n",
    "    \n",
    "    da = xr.merge([eval(v).rename(v) for v in [\"ffmc\", \"dmc\", \"dc\", \"isi\", \"bui\", \"fwi\"]])\n",
    "    \n",
    "    # remove the first year as a spin-up period\n",
    "    da = da.sel(time = slice(\"1952\", None))\n",
    "    da.to_netcdf(\"model_fwi/fwi_\"+fnm+\".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06b0611-8d50-4963-b911-d710491817ac",
   "metadata": {},
   "source": [
    "## **Time series for climate explorer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1598a55-acfa-4350-9b6a-8a16220842ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = sf.to_crs(lens_proj)\n",
    "da = xr.open_dataset(\"../00_WWA_project_folder/ephemeral/canada_fwi/can_lens/r1_r1/tas_NAM-44_CCCma-CanESM2_historical-r1_r1i1p1_CCCma-CanRCM4_r2_3hr_1950010103-1951010100.nc\").tas\n",
    "rm = regionmask.mask_3D_geopandas(sf, da.rlon, da.rlat).squeeze(drop = True)\n",
    "\n",
    "fl = glob.glob(\"../00_WWA_project_folder/ephemeral/canada_fwi/fwi/cordex/*.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fd38f7-838e-44b3-8fbe-fae37b79f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fnm in fl:\n",
    "    mdl = \"_\".join(fnm.split(\"/\")[-1].split(\"_\")[1:5])\n",
    "    fwi = xr.open_dataset(fnm).fwi.where(rm == 1).squeeze(drop = True)\n",
    "    xydims = [\"rlat\", \"rlon\"]\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    ## FWI7x FOR CLIMATE EXPLORER\n",
    "    \n",
    "    # calculate indices & cut off first year\n",
    "    fwi7x_ts = fwi.rolling(time = 7).mean().resample(time = \"AS-JAN\").max().isel(time = slice(1, None)).where(rm == 1).mean(xydims).dropna(\"time\", \"any\")\n",
    "    fwi7x_ts = fwi7x_ts.assign_coords(time = fwi7x_ts.time.dt.year).rename(time = \"year\")\n",
    "    \n",
    "    # specify filename\n",
    "    csv_fnm = \"ts/canada-wildfires_fwi7x_\"+mdl+\".dat\"\n",
    "    if len(csv_fnm.split(\"/\")[-1]) > 65: print(\"! Filename too long: \", csv_fnm)\n",
    "\n",
    "    # create extra header lines for upload to Climate Explorer \n",
    "    str1 = \"# contact :: \"+mdl+\" fwi7x - Canada wildfires 2023, c.barnes22@imperial.ac.uk\"\n",
    "    str2 = \"# fwi7x [] spatial mean of maximum of 7-day average of FWI over Eastern James Bay region at \"+re.sub(\".dat\", \"\", csv_fnm.split(\"/\")[-1])\n",
    "    head = \"# year fwi7x\"\n",
    "\n",
    "    # make .dat file\n",
    "    ! echo \"$str1 \" > $csv_fnm\n",
    "    ! echo \"$str2\" >> $csv_fnm\n",
    "    ! echo \"$head\" >> $csv_fnm\n",
    "    fwi7x_ts.to_dataframe().to_csv(csv_fnm, sep = \" \", mode = \"a\", header = False)\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    ## cumDSR FOR CLIMATE EXPLORER\n",
    "    \n",
    "    # compute DSR, set missing values to zero and mask off study region\n",
    "    dsr = (fwi ** 1.71) * 0.0272\n",
    "    dsr = dsr.where(~np.isnan(dsr), 0).where(rm == 1)\n",
    "    \n",
    "    cumdsr_ts = dsr.sel(time = [m <= 7 for m in dsr.time.dt.month]).resample(time = \"AS-JAN\").sum().rename(\"cumdsr\").where(rm == 1).mean(xydims)\n",
    "    cumdsr_ts = cumdsr_ts.assign_coords(time = cumdsr_ts.time.dt.year).rename(time = \"year\")\n",
    "    \n",
    "    # specify filename\n",
    "    csv_fnm = \"ts/canada-wildfires_cumDSR_\"+mdl+\".dat\"\n",
    "    if len(csv_fnm.split(\"/\")[-1]) > 65: print(\"! Filename too long: \", csv_fnm)\n",
    "\n",
    "    # create extra header lines for upload to Climate Explorer \n",
    "    str1 = \"# contact :: \"+mdl+\" cumulative DSR - Canada wildfires 2023, c.barnes22@imperial.ac.uk\"\n",
    "    str2 = \"# cumDSR [] spatial mean of cumulative Daily Severity Rating from Jan-July each year over Eastern James Bay region at \"+re.sub(\".dat\", \"\", csv_fnm.split(\"/\")[-1])\n",
    "    head = \"# year cumDSR\"\n",
    "\n",
    "    # make .dat file\n",
    "    ! echo \"$str1 \" > $csv_fnm\n",
    "    ! echo \"$str2\" >> $csv_fnm\n",
    "    ! echo \"$head\" >> $csv_fnm\n",
    "    cumdsr_ts.to_dataframe().to_csv(csv_fnm, sep = \" \", mode = \"a\", header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf410d1-39a2-4f9b-ac62-ad970f9672b7",
   "metadata": {},
   "source": [
    "---\n",
    "# **CMIP6**\n",
    "Data retrieved from JASMIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7230f9-59d8-4396-8878-9dd9c0b83d57",
   "metadata": {},
   "source": [
    "## **Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42792e45-4ea7-4a94-8ad6-ec1f2b027bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, check data availability - don't waste time downloading if some variables are missing\n",
    "has_data = []\n",
    "for fp in glob.glob(\"/badc/cmip6/data/CMIP6/ScenarioMIP/*/*/ssp585/r*i1p1f*/day/snw/*/latest\"):\n",
    "    \n",
    "    fp_hist = \"/\".join(fp.split(\"/\")[:5])+\"/CMIP/\"+\"/\".join(fp.split(\"/\")[6:8])+\"/historical/\"+\"/\".join(fp.split(\"/\")[9:])\n",
    "\n",
    "    fl_snw = sorted(glob.glob(fp_hist+\"/*.nc\") + glob.glob(fp+\"/*.nc\"))    \n",
    "    fl_sfcWind = sorted(glob.glob(re.sub(\"snw\", \"sfcWind\", fp_hist)+\"/*.nc\") + glob.glob(re.sub(\"snw\", \"sfcWind\", fp)+\"/*.nc\"))\n",
    "\n",
    "    fp = re.sub(\"day\", \"3hr\", fp)\n",
    "    fp_hist = re.sub(\"day\", \"3hr\", fp_hist)\n",
    "                \n",
    "    fl_huss = sorted(glob.glob(re.sub(\"snw\", \"huss\", fp_hist)+\"/*.nc\") + glob.glob(re.sub(\"snw\", \"tas\", fp)+\"/*.nc\"))\n",
    "    fl_tas = sorted(glob.glob(re.sub(\"snw\", \"tas\", fp_hist)+\"/*.nc\") + glob.glob(re.sub(\"snw\", \"tas\", fp)+\"/*.nc\"))\n",
    "    fl_pr = sorted(glob.glob(re.sub(\"snw\", \"pr\", fp_hist)+\"/*.nc\") + glob.glob(re.sub(\"snw\", \"pr\", fp)+\"/*.nc\"))\n",
    "    fl_ps = sorted(glob.glob(re.sub(\"snw\", \"ps\", fp_hist)+\"/*.nc\") + glob.glob(re.sub(\"snw\", \"ps\", fp)+\"/*.nc\"))\n",
    "\n",
    "    if any([len(eval(\"fl_\"+v)) == 0 for v in [\"snw\",\"sfcWind\", \"huss\",\"tas\",\"pr\",\"ps\"]]): continue\n",
    "    if any([eval(\"fl_\"+v)[0][-20:-16] > \"1950\" for v in [\"snw\",\"sfcWind\"]] + [eval(\"fl_\"+v)[0][-28:-24] > \"1950\" for v in [\"huss\",\"tas\",\"pr\",\"ps\"]]): continue\n",
    "    if any([eval(\"fl_\"+v)[-1][-11:-7] < \"2050\" for v in [\"snw\",\"sfcWind\"]] + [eval(\"fl_\"+v)[-1][-15:-11] < \"2050\" for v in [\"huss\",\"tas\",\"pr\",\"ps\"]]): continue\n",
    "        \n",
    "    has_data.append(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec10c2-3d66-419f-b8ed-7718b6530f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now loop over models that do have all required variables, and cut out the bits we need\n",
    "for fp in has_data:\n",
    "\n",
    "    fp_hist = \"/\".join(fp.split(\"/\")[:5])+\"/CMIP/\"+\"/\".join(fp.split(\"/\")[6:8])+\"/historical/\"+\"/\".join(fp.split(\"/\")[9:])\n",
    "    print(fp_hist)\n",
    "\n",
    "    fl_snw = sorted(glob.glob(fp_hist+\"/*.nc\") + glob.glob(fp+\"/*.nc\"))  \n",
    "    \n",
    "    for v in [\"snw\", \"sfcWind\"]:\n",
    "\n",
    "        fl = sorted(glob.glob(re.sub(\"3hr\", \"day\", re.sub(\"snw\", v, fp_hist))+\"/*.nc\") + glob.glob(re.sub(\"3hr\", \"day\", re.sub(\"snw\", v, fp))+\"/*.nc\"))\n",
    "        fl = [fnm for fnm in fl if fnm[-20:-16] <= \"2050\"]\n",
    "        \n",
    "        for fnm in fl:\n",
    "            new_fnm = \"cmip6_raw/\"+fnm.split(\"/\")[-1]\n",
    "            if not path.exists(new_fnm):\n",
    "                da = xr.open_dataset(fnm)[v].squeeze(drop = True).reset_coords(drop = True).sel(lon = slice(xn, xx), lat = slice(yn,yx), time = slice(None, \"2050\"))\n",
    "                da.to_netcdf(\"cmip6_raw/\"+fnm.split(\"/\")[-1])\n",
    "\n",
    "    for v in [\"huss\",\"tas\",\"ps\"]:\n",
    "\n",
    "        fl = sorted(glob.glob(re.sub(\"snw\", v, fp_hist)+\"/*.nc\") + glob.glob(re.sub(\"snw\", v, fp)+\"/*.nc\"))\n",
    "        fl = [fnm for fnm in fl if fnm[-28:-24] <= \"2050\"]\n",
    "\n",
    "        for fnm in fl:\n",
    "            new_fnm = \"cmip6_raw/\"+fnm.split(\"/\")[-1]\n",
    "            if not path.exists(new_fnm):\n",
    "                da = xr.open_dataset(fnm)[v].squeeze(drop = True).reset_coords(drop = True).sel(lon = slice(xn, xx), lat = slice(yn,yx), time = slice(None, \"2050\"))\n",
    "                da = da.sel(time = da.time.dt.hour == 12)\n",
    "                da.to_netcdf(\"cmip6_raw/\"+fnm.split(\"/\")[-1])\n",
    "\n",
    "    for v in [\"pr\"]:\n",
    "\n",
    "        fl = sorted(glob.glob(re.sub(\"snw\", v, fp_hist)+\"/*.nc\") + glob.glob(re.sub(\"snw\", v, fp)+\"/*.nc\"))\n",
    "        fl = [fnm for fnm in fl if fnm[-28:-24] <= \"2050\"]\n",
    "\n",
    "        for fnm in fl:\n",
    "            new_fnm = \"cmip6_raw/\"+fnm.split(\"/\")[-1]\n",
    "            if not path.exists(new_fnm):\n",
    "                da = xr.open_dataset(fnm)[v].squeeze(drop = True).reset_coords(drop = True).sel(lon = slice(xn, xx), lat = slice(yn,yx), time = slice(None, \"2050\"))\n",
    "                da.to_netcdf(\"cmip6_raw/\"+fnm.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b68ac-74a3-4afe-b837-404f078046de",
   "metadata": {},
   "source": [
    "### **Aggregate precip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b606f0d8-f076-4d5f-9380-75b4a644155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_list = sorted(list(set([re.sub(\"ssp585\", \"historical\", fnm)[:-29] for fnm in glob.glob(\"cmip6_raw/pr*\")])))\n",
    "for mdl in pr_list:\n",
    "    \n",
    "    print(datetime.now(), mdl)\n",
    "    \n",
    "    new_fnm = \"cmip6/\"+re.sub(\"3hr\",\"24hr\",mdl.split(\"/\")[-1])+\".nc\"\n",
    "    if not path.exists(new_fnm): \n",
    "\n",
    "        da = xr.open_mfdataset(re.sub(\"historical\", \"*\", mdl)+\"*.nc\").pr\n",
    "\n",
    "        if 12 in da.time.dt.hour:\n",
    "            h = 12    # assuming that label is given to end of 3hr time slice, so 12:00 corresponds to 9-12\n",
    "        else:\n",
    "            h = 10     # assuming that label is given to midpoint of 3hr time slice, so 10:30 corresponds to 9-12\n",
    "        pr24 = convert_units_to(da.rolling(time = 8).sum().groupby(\"time.hour\")[h], \"mm/day\")\n",
    "        pr24.to_netcdf(new_fnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e85051-82f6-4fc5-8e91-60aae982aed3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Relative humidity from huss, tas, ps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0006a98b-6b88-4e56-b044-1a483e008185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huss_list = sorted(list(set([re.sub(\"ssp585\", \"historical\", fnm)[:-29] for fnm in glob.glob(\"cmip6_raw/huss*\")])))\n",
    "\n",
    "for mdl in huss_list:\n",
    "        \n",
    "    new_fnm = \"cmip6/\"+re.sub(\"huss\",\"hurs\",mdl.split(\"/\")[-1])+\".nc\"\n",
    "    print(datetime.now(), new_fnm)\n",
    "    \n",
    "    if not path.exists(new_fnm): \n",
    "        huss = xr.open_mfdataset(re.sub(\"historical\", \"*\", mdl)+\"*.nc\").huss\n",
    "        tas = xr.open_mfdataset(re.sub(\"huss\", \"tas\", re.sub(\"historical\", \"*\", mdl)+\"*.nc\")).tas\n",
    "        ps = xr.open_mfdataset(re.sub(\"huss\", \"ps\", re.sub(\"historical\", \"*\", mdl)+\"*.nc\")).ps\n",
    "        hurs = relative_humidity(tas = tas, huss = huss, ps = ps).rename(\"hurs\")\n",
    "        hurs.to_netcdf(new_fnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb05f56-87f3-4f16-ba9e-21b54dad4654",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Compile everything else**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b29e27-ad76-4fc7-8083-b842d80f5c00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3hrly variables\n",
    "for varnm in [\"tas\"]:\n",
    "    mdl_list = sorted(list(set([re.sub(\"ssp585\", \"historical\",fnm)[:-29] for fnm in glob.glob(\"cmip6_raw/\"+varnm+\"*\")])))\n",
    "\n",
    "    for mdl in mdl_list:\n",
    "        \n",
    "        new_fnm = \"cmip6/\"+mdl.split(\"/\")[-1]+\".nc\"\n",
    "        print(datetime.now(), mdl)\n",
    "\n",
    "        if not path.exists(new_fnm): \n",
    "            da = convert_units_to(xr.open_mfdataset(re.sub(\"historical\", \"*\", mdl)+\"*.nc\")[varnm], \"degC\")\n",
    "            da.to_netcdf(new_fnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "637748b3-7720-41e5-8ed9-3aa9a10472e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# daily variables\n",
    "for varnm in [\"sfcWind\", \"snw\"]:\n",
    "    mdl_list = sorted(list(set([re.sub(\"ssp585\", \"historical\",fnm)[:-21] for fnm in glob.glob(\"cmip6_raw/\"+varnm+\"*\")])))\n",
    "\n",
    "    for mdl in mdl_list:\n",
    "        \n",
    "        new_fnm = \"cmip6/\"+mdl.split(\"/\")[-1]+\".nc\"\n",
    "        print(datetime.now(), new_fnm)\n",
    "\n",
    "        if not path.exists(new_fnm): \n",
    "            da = xr.open_mfdataset(re.sub(\"historical\", \"*\", mdl)+\"*.nc\")[varnm]\n",
    "            da.to_netcdf(new_fnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9437431-e475-4382-bab3-f24bd97ecc07",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Model evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e58a4a6-1510-43af-a27c-cf73a0d61dad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Seasonal cycle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5f97de8-a535-457f-ba3d-6d2fb5ba5bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for varnm in [\"tas\", \"pr\"]:\n",
    "    \n",
    "    units = {\"tas\" : \"degC\", \"pr\" : \"mm/day\"}[varnm]\n",
    "    \n",
    "    cmip6_fl = sorted(glob.glob(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/cmip6/\"+varnm+\"tas_*\"))\n",
    "    for i in range(len(cmip6_fl)):\n",
    "        da = xr.open_dataset(cmip6_fl[i])[varnm].sel(time = slice(\"1980\", \"2020\"))\n",
    "        sc = convert_units_to(da.where(regionmask.mask_3D_geopandas(sf, da.lon, da.lat).squeeze(drop = True) == 1).mean([\"lat\", \"lon\"]).groupby(\"time.dayofyear\").mean(), units)\n",
    "        sc.to_csv(\"eval/sc-\"+re.sub(\".nc\", \".csv\", fnm).split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffff3d3-0046-4ac5-9a52-aebfefe6a2a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Spatial pattern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c8505d4-6716-4bdd-98cc-4925135f9745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lat-lon bounds for Canada\n",
    "xn = 360-145; xx = 360-50; yn = 40; yx = 80\n",
    "\n",
    "# loop over models that do have all required variables, and cut out the bits we need (save everything separately as otherwise it crunches to a halt)\n",
    "for varnm in [\"tas\", \"pr\"]:    \n",
    "    for fp in has_data:\n",
    "\n",
    "        # list historical files (want 1980-2010 climatology only)\n",
    "        fl = glob.glob(re.sub(\"snw\", varnm, re.sub(\"3hr\", \"day\", re.sub(\"ssp585\", \"historical\", re.sub(\"ScenarioMIP\", \"CMIP\", fp))))+\"/*.nc\")\n",
    "        fl = [fnm for fnm in fl if (fnm[-11:-7] >= \"1980\") and (fnm[-20:-16] <= \"2020\")]\n",
    "\n",
    "        da = xr.open_mfdataset(fl)[varnm].sel(lon = slice(xn, xx), lat = slice(yn,yx), time = slice(\"1980\", \"2010\")).groupby(\"time.month\").mean().reset_coords(drop = True)\n",
    "        da.to_netcdf(\"spatial/sp-\"+re.sub(\"_[0-9]{8}-[0-9]{8}\", \"\", fl[0].split(\"/\")[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34767741-a935-4d0a-bd6f-b1cc7eaf31eb",
   "metadata": {},
   "source": [
    "---\n",
    "## **Manual calculation of FWI**\n",
    "_About 5-10 minutes per run_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c624bac9-533a-47a9-8522-3fbd86edd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/cmip6/\"\n",
    "fl = [\"_\".join(fnm.split(\"_\")[-4:]) for fnm in glob.glob(fpath+\"tas_*.nc\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7e7e3-cdb3-4dcf-9451-29c911569f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fnm in fl:\n",
    "    \n",
    "    print(fnm)\n",
    "        \n",
    "    # load data & align timestamps\n",
    "    tas = convert_units_to(xr.open_mfdataset(fpath+\"tas_*\"+fnm).tas.sel(time = slice(\"1850\", \"2049\")).load(), \"degC\")\n",
    "    pr = convert_units_to(xr.open_mfdataset(fpath+\"pr_*\"+fnm).pr.load(), \"mm/day\")\n",
    "    sfcWind = convert_units_to(xr.open_mfdataset(fpath+\"sfcWind_*\"+fnm).sfcWind.load(), \"km/hr\")\n",
    "    hurs = xr.open_mfdataset(fpath+\"hurs_*\"+fnm).hurs.load()\n",
    "    snw = convert_units_to(xr.open_mfdataset(fpath+\"snw_*\"+fnm).snw.load(), \"m\")\n",
    "    \n",
    "    if not all([len(da.time) == len(tas.time) for da in [pr, sfcWind, hurs, snw]]):\n",
    "        print(\"   ! length mismatch - skipping\")\n",
    "        continue\n",
    "    \n",
    "    P, W, H, S = [da.sel(lon = tas.lon, lat = tas.lat, time = slice(\"1850\", \"2049\")).assign_coords(time = tas.time) for da in [pr, sfcWind, hurs, snw]]\n",
    "\n",
    "    months = tas.time.dt.month.to_numpy()\n",
    "    days = tas.time.dt.day.to_numpy()\n",
    "    \n",
    "    print(\"  \",datetime.now())\n",
    "    ffmc, dmc, dc, isi, bui, fwi = xr.apply_ufunc(lambda t, p, w, h, s : calculate_fwi(months, days, t, p, w, h, s), tas, P, W, H, S, \n",
    "                                                  input_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], \n",
    "                                                  output_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], vectorize = True)\n",
    "    print(\"  \",datetime.now())\n",
    "    \n",
    "    da = xr.merge([eval(v).rename(v) for v in [\"ffmc\", \"dmc\", \"dc\", \"isi\", \"bui\", \"fwi\"]])\n",
    "    da.to_netcdf(\"model_fwi/fwi_\"+fnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ac71b-c307-4215-bc15-d7a8091f7437",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "---\n",
    "# **CORDEX**\n",
    "Raw data downloaded using synda with `local_path_drs_template=%(domain)s%(driving_model)s/%(ensemble)s/%(rcm_name)s/%(variable)s`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9602a8c5-9d9a-4be4-83b2-5fffc7c37f54",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Pre-processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d63b9-6f23-472c-920e-acb666afac5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Subset data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433a4e74-45a2-41e7-afa2-6b6994d81f22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "# script to subset each subfile of the large ensemble (concatenation done separately)\n",
    "# Chaining fails for some reason, so using an intermediate temporary file\n",
    "module load cdo\n",
    "\n",
    "tmp_file=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/99_processing/tmp.nc\n",
    "\n",
    "# temperature (only 16:30)\n",
    "fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/synda/data/*-*/*/*/tas/tas_*.nc`\n",
    "for file_in in $fl; do\n",
    "    file_out=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/99_processing/cordex/${file_in##*/};\n",
    "    cdo -s sellonlatbox,280,297,47,59 $file_in $tmp_file;\n",
    "    cdo -s selhour,16 $tmp_file $file_out;\n",
    "done\n",
    "echo \"tas complete\"\n",
    "\n",
    "# relative humidity (only 16:30)\n",
    "fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/synda/data/*-*/*/*/hurs/hurs_*.nc`\n",
    "for file_in in $fl; do\n",
    "    file_out=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/99_processing/cordex/${file_in##*/};\n",
    "    cdo -s sellonlatbox,280,297,47,59 $file_in $tmp_file;\n",
    "    cdo -s selhour,16 $tmp_file $file_out;\n",
    "done\n",
    "echo \"hurs complete\"\n",
    "\n",
    "# wind speed (only 16:30)\n",
    "fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/synda/data/*-*/*/*/sfcWind/sfcWind_*.nc`\n",
    "for file_in in $fl; do\n",
    "    file_out=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/99_processing/cordex/${file_in##*/};\n",
    "    cdo -s sellonlatbox,280,297,47,59 $file_in $tmp_file;\n",
    "    cdo -s selhour,16 $tmp_file $file_out;\n",
    "done\n",
    "echo \"sfcWind complete\"\n",
    "\n",
    "# precip (all)\n",
    "fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/synda/data/*-*/*/*/pr/pr_*.nc`\n",
    "for file_in in $fl; do\n",
    "    file_out=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/99_processing/cordex/${file_in##*/};\n",
    "    cdo -s sellonlatbox,280,297,47,59 $file_in $file_out;\n",
    "done\n",
    "echo \"pr complete\"\n",
    "\n",
    "# snow (all)\n",
    "fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/synda/data/*-*/*/*/snw/snw_*.nc`\n",
    "for file_in in $fl; do\n",
    "    file_out=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/99_processing/cordex/${file_in##*/};\n",
    "    cdo -s sellonlatbox,280,297,47,59 $file_in $file_out;\n",
    "done;\n",
    "echo \"snw complete\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1588590b-030c-45e6-ab9f-f731c9f734f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Concatenate subsetted data (excluding precip)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca2dee-be1f-4dec-9697-2f0941277309",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "# script to concatenate subfiles of CORDEX runs\n",
    "module load cdo\n",
    "\n",
    "for varnm in tas sfcWind snw hurs; do\n",
    "    for mdl in HadGEM2 MPI-ESM NorESM; do \n",
    "        \n",
    "        fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/99_processing/cordex/${varnm}_*${mdl}*.nc`;\n",
    "        \n",
    "        fnm_root=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/99_processing/cordex/${varnm}_*${mdl}*.nc | head -1`;\n",
    "        fnm_root=${fnm_root##*/};\n",
    "        new_fnm=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/cordex/${fnm_root/_1970*/.nc};\n",
    "        cdo cat $fl $new_fnm; \n",
    "    done\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6e133-2509-4562-9d62-289a9d0ab4dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Concatenate & aggregate precipitation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1879c312-2006-46e3-aa50-7a256af6f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../00_WWA_project_folder/ephemeral/canada_fwi/99_processing/cordex\"\n",
    "cordex_models = [\"HadGEM2\", \"MPI-ESM\", \"NorESM\"]\n",
    "path_out = \"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/cordex/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca15eea9-9ffc-41ab-9e7b-28de322d5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl in cordex_models:\n",
    "    fl = glob.glob(fpath+\"/pr_*\"+mdl+\"*.nc\")\n",
    "    new_fnm = path_out+fl[0].split(\"/\")[-1][:-32]+\"24hr-1630.nc\"\n",
    "    da = xr.open_mfdataset(fl).pr\n",
    "    da = da.rolling(time = 8).sum().groupby(\"time.hour\")[16]\n",
    "    da.to_netcdf(new_fnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75efaf2e-3eb7-4383-89fc-bdc7a7f17d63",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Model evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116971a3-22ba-4567-a05d-c82af428f078",
   "metadata": {},
   "source": [
    "### **Seasonal cycle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b294e130-773f-42cd-8c58-3b84db2b8e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for varnm in [\"tas\", \"pr\"]:\n",
    "    \n",
    "    units = {\"tas\" : \"degC\", \"pr\" : \"mm/day\"}[varnm]\n",
    "    \n",
    "    cordex_fl = sorted(glob.glob(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/cordex/\"+varnm+\"_*\"))\n",
    "    for i in range(len(cordex_fl)):\n",
    "        fnm = cordex_fl[i]\n",
    "        da = xr.open_dataset(fnm).tas.sel(time = slice(\"1980\", \"2020\"))\n",
    "        sc = convert_units_to(da.where(regionmask.mask_3D_geopandas(sf, da.lon, da.lat).squeeze(drop = True) == 1).mean([\"rlat\", \"rlon\"]).groupby(\"time.dayofyear\").mean(), units)\n",
    "        sc.to_csv(\"eval/sc-\"+re.sub(\".nc\", \".csv\", fnm).split(\"/\")[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18dd3f-d59e-46a6-acf2-a873bc752f35",
   "metadata": {},
   "source": [
    "### **Spatial pattern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1f5ffe1-a041-4aa6-b4fa-0f1d47a9b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat-lon bounds for Canada (all runs use same grid in this case)\n",
    "xn = 360-145; xx = 360-50; yn = 40; yx = 80\n",
    "\n",
    "tmplt = xr.open_dataset(\"../00_WWA_project_folder/ephemeral/canada_fwi/synda/data/MOHC-HadGEM2-ES/r1i1p1/REMO2015/tas/tas_NAM-22_MOHC-HadGEM2-ES_historical_r1i1p1_GERICS-REMO2015_v1_3hr_197001010100-197012302200.nc\")\n",
    "rm = np.logical_and(np.logical_and(tmplt.lon >= xn, tmplt.lon <= xx), np.logical_and(tmplt.lat >= yn, tmplt.lat <= yx))\n",
    "rm = rm.where(rm == 1).dropna(\"rlon\", \"all\").dropna(\"rlat\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0493c0-b7a9-402b-a43d-c4f6f2c9d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "for varnm in [\"tas\", \"pr\"]:\n",
    "    \n",
    "    units = {\"tas\" : \"degC\", \"pr\" : \"mm/day\"}[varnm]\n",
    "\n",
    "    for fp in glob.glob(\"../00_WWA_project_folder/ephemeral/canada_fwi/synda/data/*/r1i1p1/REMO2015/\"+varnm):\n",
    "\n",
    "        print(fp, end = \"\")\n",
    "        fl = glob.glob(fp+\"/*.nc\")\n",
    "        fl = [fnm for fnm in fl if (fnm[-15:-11] >= \"1980\") & (fnm[-28:-24] <= \"2010\")]\n",
    "\n",
    "        em = []\n",
    "        for fnm in fl:\n",
    "            print(\".\", end = \"\")\n",
    "            em.append(xr.open_dataset(fnm)[varnm].sel(rlon = rm.rlon, rlat = rm.rlat).groupby(\"time.season\")[\"JJA\"].mean(\"time\"))\n",
    "        em = convert_units_to(xr.concat(em, \"time\").mean(\"time\"), units)\n",
    "        em.to_netcdf(\"sp-\"+\"_\".join(fl[0].split(\"/\")[-1].split(\"_\")[:-2])+\".nc\")\n",
    "        print(\"\")\n",
    "    clear_output(wait = False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e140c-861c-4829-8e85-beff60285a49",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Calculate FWI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "609b3f54-d990-45bd-9860-aa3c736bc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/cordex/\"\n",
    "fl = [\"_\".join(fnm.split(\"_\")[-7:-2]) for fnm in glob.glob(fpath+\"tas_*.nc\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd105b94-139a-46f0-8201-87899bfa2963",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fnm in fl:\n",
    "    \n",
    "    print(fnm)\n",
    "        \n",
    "    # load data & align timestamps\n",
    "    tas = convert_units_to(xr.open_mfdataset(fpath+\"tas_*\"+fnm+\"*.nc\").tas.load(), \"degC\")\n",
    "    pr = convert_units_to(xr.open_mfdataset(fpath+\"pr_*\"+fnm+\"*.nc\").pr.load(), \"mm/day\")\n",
    "    sfcWind = convert_units_to(xr.open_mfdataset(fpath+\"sfcWind_*\"+fnm+\"*.nc\").sfcWind.load(), \"km/hr\")\n",
    "    hurs = xr.open_mfdataset(fpath+\"hurs_*\"+fnm+\"*.nc\").hurs.load()\n",
    "    snw = convert_units_to(xr.open_mfdataset(fpath+\"snw_*\"+fnm+\"*.nc\").snw.load(), \"m\")\n",
    "    \n",
    "    # check that all time series are the same length\n",
    "    if not all([len(da.time) == len(tas.time) for da in [pr, sfcWind, hurs, snw]]):\n",
    "        print(\"   ! length mismatch - skipping\")\n",
    "        continue\n",
    "        \n",
    "    P, W, H, S = [da.sel(rlon = tas.rlon, rlat = tas.rlat).assign_coords(time = tas.time) for da in [pr, sfcWind, hurs, snw]]\n",
    "        \n",
    "    months = tas.time.dt.month.to_numpy()\n",
    "    days = tas.time.dt.day.to_numpy()\n",
    "    \n",
    "    print(\"  \",datetime.now())\n",
    "    ffmc, dmc, dc, isi, bui, fwi = xr.apply_ufunc(lambda t, p, w, h, s : calculate_fwi(months, days, t, p, w, h, s), tas, P, W, H, S, \n",
    "                                                  input_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], \n",
    "                                                  output_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], vectorize = True)\n",
    "    print(\"  \",datetime.now())\n",
    "    \n",
    "    da = xr.merge([eval(v).rename(v) for v in [\"ffmc\", \"dmc\", \"dc\", \"isi\", \"bui\", \"fwi\"]])\n",
    "    da.to_netcdf(\"model_fwi/fwi_\"+fnm+\".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230390d0-3e2b-4908-a35a-27909a3e8ba1",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "---\n",
    "# **HighresMIP**\n",
    "Data retrieved from JASMIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ce4b6-4f28-4034-95bc-b6549a21ab9e",
   "metadata": {},
   "source": [
    "## **Extract variables from archived data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b7b07-9595-4b3b-ba66-8ab27e6ada6d",
   "metadata": {},
   "source": [
    "### **Noon temperatures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d8f28-415b-4fcb-9bc2-fdf8255a7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_list = [fp for fp in glob.glob(\"/badc/cmip6/data/CMIP6/HighResMIP/*/EC-Earth*/highresSST-future/*/3hr/tas/*/latest/\") if not \"r1i1p1f1\" in fp]\n",
    "for fpath in tas_list:\n",
    "    \n",
    "    fl = glob.glob(re.sub(\"future\", \"present\", fpath)+\"/*\") + glob.glob(fpath+\"/*\")\n",
    "    fl = [fnm for fnm in fl if not \"highresmip_raw/\"+re.sub(\"3hr\", \"1800\", fnm).split(\"/\")[-1] in glob.glob(\"highresmip_raw/tas_*.nc\")]\n",
    "\n",
    "    for fnm in fl:\n",
    "        new_fnm = \"highresmip_raw/\"+re.sub(\"3hr\", \"1800\", fnm).split(\"/\")[-1]\n",
    "        print(new_fnm)\n",
    "        da = xr.open_dataset(fnm).sel(lon = slice(xn, xx), lat = slice(yn,yx)).reset_coords(drop = True).tas.groupby(\"time.hour\")[18]\n",
    "        da.to_netcdf(new_fnm)\n",
    "    clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fceac2b-61b0-4a49-b64a-2ccfdfda6e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl in list(set([re.sub(\"future\", \"present\", fnm)[:-29] for fnm in glob.glob(\"highresmip_raw/tas_*\")])):\n",
    "    da = xr.open_mfdataset(re.sub(\"present\", \"*\", mdl)+\"*.nc\")\n",
    "    da.to_netcdf(\"highresmip/\"+mdl.split(\"/\")[-1]+\".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3808f8e7-c1db-41b2-9d75-3e445b9ac97f",
   "metadata": {},
   "source": [
    "### **Noon relative humidity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409bde6-6771-4b85-bbcc-3265bb30cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut out relevant area & timestamps\n",
    "huss_list = [fp for fp in glob.glob(\"/badc/cmip6/data/CMIP6/HighResMIP/*/EC-Earth*/highresSST-future/*/3hr/huss/*/latest/\") if not \"r1i1p1f1\" in fp]\n",
    "for fpath in huss_list:\n",
    "\n",
    "    fl = glob.glob(re.sub(\"future\", \"present\", fpath)+\"/*\") + glob.glob(fpath+\"/*\")\n",
    "    fl = [fnm for fnm in fl if not \"highresmip_raw/\"+re.sub(\"huss\", \"hurs\",re.sub(\"3hr\", \"1800\", fnm)).split(\"/\")[-1] in glob.glob(\"highresmip_raw/hurs_*.nc\")]\n",
    "\n",
    "    for fnm in fl:\n",
    "        new_fnm = \"highresmip_raw/\"+re.sub(\"huss\", \"hurs\",re.sub(\"3hr\", \"1800\", fnm)).split(\"/\")[-1]\n",
    "        print(new_fnm)\n",
    "\n",
    "        huss, tas, ps = [xr.open_dataset(re.sub(\"huss\", varnm, fnm)).sel(lon = slice(xn, xx), lat = slice(yn,yx), \n",
    "                                                                         time = slice(None, \"2050\")).reset_coords(drop = True)[varnm].groupby(\"time.hour\")[18] \n",
    "                         for varnm in [\"huss\", \"tas\", \"ps\"]]\n",
    "\n",
    "        hurs = relative_humidity(tas = tas, ps = ps, huss = huss).rename(\"hurs\")\n",
    "        hurs.to_netcdf(new_fnm)\n",
    "    clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24847277-8923-4586-83bf-7cc96886f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl in list(set([re.sub(\"future\", \"present\", fnm)[:-29] for fnm in glob.glob(\"highresmip_raw/hurs_*\")])):\n",
    "    da = xr.open_mfdataset(re.sub(\"present\", \"*\", mdl)+\"*.nc\")\n",
    "    da.to_netcdf(\"highresmip/\"+mdl.split(\"/\")[-1]+\".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b1d70-0701-4415-9a29-29ad71feadfc",
   "metadata": {},
   "source": [
    "### **3hourly precip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55554a7-43a9-4525-a38b-76dcb7fb2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut out relevant area - can't aggregate until all files are subsetted\n",
    "pr_list = [fp for fp in glob.glob(\"/badc/cmip6/data/CMIP6/HighResMIP/*/EC-Earth*/highresSST-future/*/3hr/pr/*/latest/\") if not \"r1i1p1f1\" in fp]\n",
    "for fpath in pr_list:\n",
    "\n",
    "    fl = glob.glob(re.sub(\"future\", \"present\", fpath)+\"/*\") + glob.glob(fpath+\"/*\")\n",
    "    fl = [fnm for fnm in fl if not \"highresmip_raw/\"+fnm.split(\"/\")[-1] in glob.glob(\"highresmip_raw/pr_*.nc\")]\n",
    "\n",
    "    for fnm in fl:\n",
    "        new_fnm = \"highresmip_raw/\"+fnm.split(\"/\")[-1]\n",
    "        print(new_fnm)\n",
    "        da = xr.open_dataset(fnm).sel(lon = slice(xn, xx), lat = slice(yn,yx)).reset_coords(drop = True).pr\n",
    "        da.to_netcdf(new_fnm)\n",
    "    clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee480ad4-4fdf-402e-8bff-ab3e1d6073e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mdl in list(set([re.sub(\"future\", \"present\", fnm)[:-29] for fnm in glob.glob(\"highresmip_raw/pr_*\")])):\n",
    "    da = xr.open_mfdataset(re.sub(\"present\", \"*\", mdl)+\"*.nc\").pr\n",
    "    da = da.rolling(time = 8).sum().groupby(\"time.hour\")[18]\n",
    "    da.to_netcdf(\"highresmip/\"+re.sub(\"3hr\", \"24hr-1800\", mdl).split(\"/\")[-1]+\".nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711bfe40-4ae0-413f-983c-3e10e09400f7",
   "metadata": {},
   "source": [
    "### **Daily snow depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601f97c-17d3-4871-bdb3-0ee4072ba336",
   "metadata": {},
   "outputs": [],
   "source": [
    "snw_list = glob.glob(\"/badc/cmip6/data/CMIP6/HighResMIP/*/*/highresSST-future/*/day/snw/*/latest/\")\n",
    "for fpath in snw_list:\n",
    "    # print(fpath)\n",
    "    fl_hist = glob.glob(re.sub(\"future\", \"present\", fpath)+\"/*\")\n",
    "    fl_fut = glob.glob(fpath+\"/*\")\n",
    "\n",
    "    for fnm in (fl_hist + fl_fut):\n",
    "        new_fnm = \"highresmip_raw/\"+fnm.split(\"/\")[-1]\n",
    "        if not path.exists(new_fnm): \n",
    "            print(new_fnm)\n",
    "        # else:\n",
    "        #     print(\".\", end = \"\")\n",
    "            da = xr.open_dataset(fnm)\n",
    "            da = da.sel(lon = slice(xn, xx), lat = slice(yn,yx), time = slice(None, \"2050\")).squeeze(drop = True).reset_coords(drop = True).snw\n",
    "            da.to_netcdf(\"highresmip_raw/\"+fnm.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f5c0f-beec-4bb4-bfae-286d9382bb05",
   "metadata": {},
   "source": [
    "### **Daily sfcWind**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264aab8d-a40d-4b39-b531-c74668138ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfcWind_list = glob.glob(\"/badc/cmip6/data/CMIP6/HighResMIP/*/*/highresSST-future/*/day/sfcWind/*/latest/\")\n",
    "for fpath in sfcWind_list:\n",
    "    # print(fpath)\n",
    "    fl_hist = glob.glob(re.sub(\"future\", \"present\", fpath)+\"/*\")\n",
    "    fl_fut = glob.glob(fpath+\"/*\")\n",
    "\n",
    "    for fnm in (fl_hist + fl_fut):\n",
    "        new_fnm = \"highresmip_raw/\"+fnm.split(\"/\")[-1]\n",
    "        if not path.exists(new_fnm): \n",
    "            print(new_fnm)\n",
    "        # else:\n",
    "        #     print(\".\", end = \"\")\n",
    "        da = xr.open_dataset(fnm)\n",
    "        da = da.sel(lon = slice(xn, xx), lat = slice(yn,yx), time = slice(None, \"2050\")).squeeze(drop = True).reset_coords(drop = True).sfcWind\n",
    "        da.to_netcdf(new_fnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220ebae-237d-4594-af6c-9853c48be4d4",
   "metadata": {},
   "source": [
    "## **Model evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13c8bc-6f2e-49a3-8d97-0a630d90acc5",
   "metadata": {},
   "source": [
    "### **Seasonal cycles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923c2862-207a-4d0d-b66c-e9439ecc1433",
   "metadata": {},
   "outputs": [],
   "source": [
    "for varnm in [\"tas\", \"pr\"]:\n",
    "    \n",
    "    units = {\"tas\" : \"degC\", \"pr\" : \"mm/day\"}[varnm]\n",
    "    \n",
    "    highresmip_fl = sorted(glob.glob(\"../00_WWA_project_folder/ephemeral/canada_fwi/highresmip/\"+varnm+\"/\"+varnm+\"_*\"))\n",
    "    for i in range(len(highresmip_fl)):\n",
    "        fnm = highresmip_fl[i]\n",
    "        da = xr.open_dataset(fnm).tas.sel(time = slice(\"1980\", \"2020\"))\n",
    "        sc = convert_units_to(da.where(regionmask.mask_3D_geopandas(sf, da.lon, da.lat).squeeze(drop = True) == 1).mean([\"lat\", \"lon\"]).groupby(\"time.dayofyear\").mean(), units)\n",
    "        sc.to_csv(\"eval/sc-\"+re.sub(\".nc\", \".csv\", fnm).split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e297aa1-21b8-43d4-9023-25f8146d301f",
   "metadata": {},
   "source": [
    "### **Spatial pattern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40f156-a11b-410b-ae04-c5066b04431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat-lon bounds for Canada\n",
    "xn = 360-145; xx = 360-50; yn = 40; yx = 80\n",
    "\n",
    "mdl_list = [fp for fp in glob.glob(\"/badc/cmip6/data/CMIP6/HighResMIP/*/EC-Earth*/highresSST-future/*/3hr/tas/*/latest/\") if not \"r1i1p1f1\" in fp]\n",
    "\n",
    "# temperatures\n",
    "for fp in mdl_list:\n",
    "\n",
    "    # list historical files (want 1980-2010 climatology only)\n",
    "    fl = glob.glob(re.sub(\"3hr\", \"day\", re.sub(\"future\", \"present\", fp))+\"*.nc\")\n",
    "    fl = [fnm for fnm in fl if (fnm[-11:-7] >= \"1980\") and (fnm[-20:-16] <= \"2010\")]\n",
    "\n",
    "    da = xr.open_mfdataset(fl).tas.sel(lon = slice(xn, xx), lat = slice(yn,yx), time = slice(\"1980\", \"2010\")).groupby(\"time.month\").mean().reset_coords(drop = True)\n",
    "    da.to_netcdf(\"spatial/sp-\"+re.sub(\"_[0-9]{8}-[0-9]{8}\", \"\", fl[0].split(\"/\")[-1]))\n",
    "    \n",
    "# precip\n",
    "for fp in mdl_list:\n",
    "\n",
    "    # list historical files (want 1980-2010 climatology only)\n",
    "    fl = glob.glob(re.sub(\"tas\", \"pr\", re.sub(\"3hr\", \"day\", re.sub(\"future\", \"present\", fp)))+\"*.nc\")\n",
    "    fl = [fnm for fnm in fl if (fnm[-11:-7] >= \"1980\") and (fnm[-20:-16] <= \"2010\")]\n",
    "\n",
    "    da = xr.open_mfdataset(fl).pr.sel(lon = slice(xn, xx), lat = slice(yn,yx), time = slice(\"1980\", \"2010\")).groupby(\"time.month\").mean().reset_coords(drop = True)\n",
    "    da.to_netcdf(\"spatial/sp-\"+re.sub(\"_[0-9]{8}-[0-9]{8}\", \"\", fl[0].split(\"/\")[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01090b-616a-4446-8f2d-d578d91702bf",
   "metadata": {},
   "source": [
    "## **Manual calculation of FWI**\n",
    "Carried out after transferring raw variables to HPC, but could be done anywhere  \n",
    "_About 15 minutes per run_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699864a-a7a7-454d-b795-88cf33e5c56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC-Earth3P_highresSST-present_r2i1p1f1_gr.nc\n"
     ]
    }
   ],
   "source": [
    "fpath = \"../00_WWA_project_folder/ephemeral/canada_fwi/highresmip/\"\n",
    "fl = [\"_\".join(fnm.split(\"_\")[-4:]) for fnm in glob.glob(fpath+\"tas/*.nc\")]\n",
    "\n",
    "for fnm in fl:\n",
    "    \n",
    "    print(fnm)\n",
    "        \n",
    "    # load data & align timestamps\n",
    "    tas = convert_units_to(xr.open_mfdataset(fpath+\"tas/*\"+fnm).tas.load(), \"degC\")\n",
    "    pr = convert_units_to(xr.open_mfdataset(fpath+\"pr_24h/*\"+fnm).pr.load(), \"mm/day\")\n",
    "    sfcWind = convert_units_to(xr.open_mfdataset(fpath+\"sfcWind/*\"+fnm).sfcWind.load(), \"km/hr\")\n",
    "    hurs = xr.open_mfdataset(fpath+\"hurs/*\"+fnm).hurs.load()\n",
    "    snw = convert_units_to(xr.open_mfdataset(fpath+\"snw/*\"+fnm).snw.load(), \"m\")\n",
    "    \n",
    "    if not all([len(da.time) == len(tas.time) for da in [pr, sfcWind, hurs, snw]]):\n",
    "        print(\"   ! length mismatch - skipping\")\n",
    "        continue\n",
    "        \n",
    "    P, W, H, S = [da.sel(lon = tas.lon, lat = tas.lat).assign_coords(time = tas.time) for da in [pr, sfcWind, hurs, snw]]\n",
    "    \n",
    "    months = tas.time.dt.month.to_numpy()\n",
    "    days = tas.time.dt.day.to_numpy()\n",
    "    \n",
    "    print(\"  \",datetime.now())\n",
    "    ffmc, dmc, dc, isi, bui, fwi = xr.apply_ufunc(lambda t, p, w, h, s : calculate_fwi(months, days, t, p, w, h, s), tas, P, W, H, S, \n",
    "                                                  input_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], \n",
    "                                                  output_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], vectorize = True)\n",
    "    print(\"  \",datetime.now())\n",
    "    \n",
    "    da = xr.merge([eval(v).rename(v) for v in [\"ffmc\", \"dmc\", \"dc\", \"isi\", \"bui\", \"fwi\"]])\n",
    "    da.to_netcdf(\"model_fwi/fwi_\"+fnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80bbb47-a614-4763-a96e-33ac6854b847",
   "metadata": {},
   "source": [
    "### **FWI time series over study region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a2c278c-4daf-448a-b9fe-3c8387ef2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fnm in glob.glob(\"../00_WWA_project_folder/ephemeral/canada_fwi/fwi/highresmip/fwi_*.nc\"):\n",
    "    \n",
    "    da = xr.open_dataset(fnm).fwi\n",
    "    \n",
    "    # replace any missing values with 0 (otherwise averaging comes out with wrong numbers)\n",
    "    da = da.where(~np.isnan(da), 0)\n",
    "    \n",
    "    # average over study region\n",
    "    rm_ejb = regionmask.mask_3D_geopandas(sf, da.lon, da.lat).squeeze(drop = True)\n",
    "    ts = da.where(rm_ejb == 1).mean([\"lon\", \"lat\"])\n",
    "    \n",
    "    ts.to_netcdf(\"data/fwi-ejb_highresmip_\"+fnm.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce75c0-d026-4dbb-bf24-df29d8855449",
   "metadata": {},
   "source": [
    "### **Time series of FWI indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa677cc4-83cd-476a-818c-c6cbd3032ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwi7x_ens = []\n",
    "cumDSR_ens = []\n",
    "\n",
    "for fnm in glob.glob(\"fwi/highresmip/fwi_*.nc\"):\n",
    "    \n",
    "    fwi = xr.open_dataset(fnm).fwi\n",
    "    rm = regionmask.mask_3D_geopandas(sf, fwi.lon, fwi.lat).squeeze(drop = True)\n",
    "    \n",
    "    # get monthly time series of indices for now - then can easily modify seasonal scope if need be (eg if updating for full fire season)\n",
    "    fwi7x = convert_calendar(fwi.rolling(time = 7).mean().resample(time = \"MS\").max(), \"default\", align_on = \"date\").rename(\"fwi7x\")\n",
    "    fwi7x_ens.append(fwi7x.where(rm == 1).mean([\"lat\", \"lon\"]))\n",
    "    \n",
    "    msr = convert_calendar(fwi.resample(time = \"MS\").sum().rename(\"msr\"), \"default\", align_on = \"date\").rename(\"msr\")\n",
    "    cumDSR_ens.append(msr.where(rm == 1).mean([\"lat\", \"lon\"]))\n",
    "    \n",
    "fwi7x_ens = convert_calendar(xr.concat(fwi7x_ens, \"member\"), \"default\", align_on = \"date\").sortby(\"member\")\n",
    "cumDSR_ens = convert_calendar(xr.concat(cumDSR_ens, \"member\"), \"default\", align_on = \"date\").sortby(\"member\")\n",
    "\n",
    "fwi7x_ens.to_netcdf(\"00_model-data/fwi7x_highresMIP_EC-Earth.nc\")\n",
    "cumDSR_ens.to_netcdf(\"00_model-data/msr_highresMIP_EC-Earth.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3faf75-1738-43a2-aa93-57064e01433a",
   "metadata": {},
   "source": [
    "---\n",
    "# **UQAM-CRCM5**\n",
    "Data provided by UQAM and downloaded to HPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19cdb58-f9f8-4306-950a-2a5be517fb8e",
   "metadata": {},
   "source": [
    "## **Define projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c4b05-0632-4c2a-87cd-c33fc247d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_crcm5 = cartopy.crs.RotatedPole(pole_longitude = 83, pole_latitude = 42.5)\n",
    "sf = gpd.read_file(\"sf_ejb/\").to_crs(proj_crcm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac51722-91f6-49b1-a83a-89c1df690568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that CRS is correct\n",
    "da = xr.open_dataset(\"../00_WWA_project_folder/ephemeral/canada_fwi/99_processing/crcm5/var_HR_194901.nc4\")\n",
    "rm = regionmask.mask_3D_geopandas(sf, da.rlon, da.rlat).squeeze(drop = True)\n",
    "\n",
    "da.isel(time = -1).plot()\n",
    "sf.boundary.plot(color = \"k\", ax = plt.gca())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f6133-6edf-4f0a-a9de-844e08f72f48",
   "metadata": {},
   "source": [
    "## **Pre-processing**\n",
    "HR = hurs; I5 = snw; PR = pr; TT = tas   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc16306-0cac-41fb-a4f0-7eaf905db4fc",
   "metadata": {},
   "source": [
    "### **Convert u- and v-vectors to windspeed using CDO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf7705-0c7f-4eb2-82e9-fbc2a29c68ef",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "# script to convert u and v wind vectors to windspeed\n",
    "# Chaining fails for some reason, so using an intermediate temporary file\n",
    "\n",
    "fl=`ls crcm5/*/*UU*.nc4`\n",
    "for u_file in $fl; do\n",
    "    v_file=${u_file/UU/VV};\n",
    "    outfile=${u_file/UU/WS};\n",
    "    file_out=crcm5_wind/${outfile##*/};\n",
    "    echo $file_out;\n",
    "    cdo -s chname,uas,sfcWind -sqrt -add -sqr -selname,uas $u_file -sqr -selname,vas $v_file $file_out\n",
    "done\n",
    "echo \"sfcWind complete\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc34003-21b2-4e42-8d70-370d3c398662",
   "metadata": {},
   "source": [
    "### **Concatenate files using CDO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b9331-5530-40bc-a476-d14cea1674fd",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash\n",
    "\n",
    "# script to concatenate subfiles of CRCM5 runs\n",
    "module load cdo\n",
    "for varnm in TT I5 HR WS PR; do\n",
    "        \n",
    "    fl=`ls /rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/99_processing/crcm5/var_${varnm}_*.nc4`;\n",
    "    \n",
    "    new_fnm=/rds/general/user/cb2714/home/00_WWA_project_folder/ephemeral/canada_fwi/99_processing/crcm5_catted/crcm5_${varnm}_catted.nc;\n",
    "    cdo cat $fl $new_fnm; \n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db60212c-f948-4233-a5bc-078789db5f59",
   "metadata": {},
   "source": [
    "### **Aggregate precip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f500a28-f88c-4eab-ab78-2c82f1d52ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_in = \"../00_WWA_project_folder/ephemeral/canada_fwi/99_processing/crcm5_catted/\"\n",
    "path_out = \"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/crcm5/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf5b516-d6d5-4922-a3e7-8010341b340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate precip to daily\n",
    "pr = xr.open_dataset(cat_path+\"crcm5_PR_catted.nc\").pr\n",
    "pr24 = pr.rolling(time = 24, center = False).sum()\n",
    "pr24h = pr24.groupby(\"time.hour\")[18]\n",
    "convert_units_to(pr24h, \"mm/day\").to_netcdf(path_out+\"pr_1800_CRCM5.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd43c769-801e-4498-8719-503dcbd67858",
   "metadata": {},
   "source": [
    "### **Convert all units**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "616b2b07-6bb0-4076-bf0d-199b63d796fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all other variables to the required units\n",
    "convert_units_to(xr.open_dataset(path_in+\"crcm5_TT_catted.nc\").tas, \"degC\").to_netcdf(path_out+\"tas_1800_CRCM5.nc\")\n",
    "convert_units_to(xr.open_dataset(path_in+\"crcm5_HR_catted.nc\").hurs, \"%\").to_netcdf(path_out+\"hurs_1800_CRCM5.nc\")\n",
    "convert_units_to(xr.open_dataset(path_in+\"crcm5_WS_catted.nc\").sfcWind, \"km/hr\").to_netcdf(path_out+\"sfcWind_1800_CRCM5.nc\")\n",
    "convert_units_to(xr.open_dataset(path_in+\"crcm5_I5_catted.nc\").snw, \"m\").to_netcdf(path_out+\"snw_1800_CRCM5.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfb88f4-b5fa-4779-b12b-5e379dfd7389",
   "metadata": {},
   "source": [
    "## **Calculate FWI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191c038-66b8-4be0-866e-f66b9076cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas, pr, sfcWind, snw, hurs = [xr.open_dataset(\"../00_WWA_project_folder/ephemeral/canada_fwi/00_data-for-fwi/crcm5/\"+varnm+\"_1800_CRCM5.nc\")[varnm] for varnm in [\"tas\", \"pr\", \"sfcWind\", \"snw\", \"hurs\"]]\n",
    "\n",
    "months = tas.time.dt.month.to_numpy()\n",
    "days = tas.time.dt.day.to_numpy()\n",
    "\n",
    "print(\"  \",datetime.now())\n",
    "ffmc, dmc, dc, isi, bui, fwi = xr.apply_ufunc(lambda t, p, w, h, s : calculate_fwi(months, days, t, p, w, h, s), tas, pr, sfcWind, hurs, snw, \n",
    "                                              input_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], \n",
    "                                              output_core_dims = [[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"],[\"time\"]], vectorize = True)\n",
    "print(\"  \",datetime.now())\n",
    "\n",
    "da = xr.merge([eval(v).rename(v) for v in [\"ffmc\", \"dmc\", \"dc\", \"isi\", \"bui\", \"fwi\"]])\n",
    "da.to_netcdf(\"model_fwi/fwi_CRCM5.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639e4d6-9621-40ac-8bc3-967dab4d34bd",
   "metadata": {},
   "source": [
    "### **Time series for climate explorer**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "556c6042-18d5-4e2e-a7c3-a42803b823b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwi = xr.open_dataset(\"model_fwi/fwi_CRCM5.nc\").fwi\n",
    "\n",
    "mdl = \"CRCM5\"\n",
    "xydims = [\"rlat\", \"rlon\"]\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "## FWI7x FOR CLIMATE EXPLORER\n",
    "\n",
    "# calculate indices & cut off first year\n",
    "fwi7x_ts = fwi.rolling(time = 7).mean().resample(time = \"AS-JAN\").max().isel(time = slice(1, None)).where(rm == 1).mean(xydims).dropna(\"time\", \"any\")\n",
    "fwi7x_ts = fwi7x_ts.assign_coords(time = fwi7x_ts.time.dt.year).rename(time = \"year\")\n",
    "\n",
    "# specify filename\n",
    "csv_fnm = \"ts/canada-wildfires_fwi7x_\"+mdl+\".dat\"\n",
    "if len(csv_fnm.split(\"/\")[-1]) > 65: print(\"! Filename too long: \", csv_fnm)\n",
    "\n",
    "# create extra header lines for upload to Climate Explorer \n",
    "str1 = \"# contact :: \"+mdl+\" fwi7x - Canada wildfires 2023, c.barnes22@imperial.ac.uk\"\n",
    "str2 = \"# fwi7x [] spatial mean of maximum of 7-day average of FWI over Eastern James Bay region at \"+re.sub(\".dat\", \"\", csv_fnm.split(\"/\")[-1])\n",
    "head = \"# year fwi7x\"\n",
    "\n",
    "# make .dat file\n",
    "! echo \"$str1 \" > $csv_fnm\n",
    "! echo \"$str2\" >> $csv_fnm\n",
    "! echo \"$head\" >> $csv_fnm\n",
    "fwi7x_ts.to_dataframe().to_csv(csv_fnm, sep = \" \", mode = \"a\", header = False)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "## cumDSR FOR CLIMATE EXPLORER\n",
    "\n",
    "# compute DSR, set missing values to zero and mask off study region\n",
    "dsr = (fwi ** 1.71) * 0.0272\n",
    "dsr = dsr.where(~np.isnan(dsr), 0).where(rm == 1)\n",
    "\n",
    "cumdsr_ts = dsr.sel(time = [m <= 7 for m in dsr.time.dt.month]).resample(time = \"AS-JAN\").sum().rename(\"cumdsr\").where(rm == 1).mean(xydims)\n",
    "cumdsr_ts = cumdsr_ts.assign_coords(time = cumdsr_ts.time.dt.year).rename(time = \"year\")\n",
    "\n",
    "# specify filename\n",
    "csv_fnm = \"ts/canada-wildfires_cumDSR_\"+mdl+\".dat\"\n",
    "if len(csv_fnm.split(\"/\")[-1]) > 65: print(\"! Filename too long: \", csv_fnm)\n",
    "\n",
    "# create extra header lines for upload to Climate Explorer \n",
    "str1 = \"# contact :: \"+mdl+\" cumulative DSR - Canada wildfires 2023, c.barnes22@imperial.ac.uk\"\n",
    "str2 = \"# cumDSR [] spatial mean of cumulative Daily Severity Rating from Jan-July each year over Eastern James Bay region at \"+re.sub(\".dat\", \"\", csv_fnm.split(\"/\")[-1])\n",
    "head = \"# year cumDSR\"\n",
    "\n",
    "# make .dat file\n",
    "! echo \"$str1 \" > $csv_fnm\n",
    "! echo \"$str2\" >> $csv_fnm\n",
    "! echo \"$head\" >> $csv_fnm\n",
    "cumdsr_ts.to_dataframe().to_csv(csv_fnm, sep = \" \", mode = \"a\", header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da205b1-4a6b-4835-b25f-4eb4e905f5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wwa]",
   "language": "python",
   "name": "conda-env-wwa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
